{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_RAW_PATH = 'JNUData'\n",
    "DATA_PATH = 'data'\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.mkdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run only once\n",
    "# n-healthy, t-rolling element fault, o-outer ring fault, i-inner ring fault\n",
    "\n",
    "files_names = os.listdir(DATA_RAW_PATH)\n",
    "SAMPLES_NUMBER = 50\n",
    "SAMPLE_WINDOW = 10000\n",
    "\n",
    "for file_name in files_names:\n",
    "    file_path = os.path.join(DATA_RAW_PATH, file_name)\n",
    "    data = pd.read_csv(file_path)\n",
    "    for i in range(SAMPLES_NUMBER):\n",
    "        sample = data.iloc[i*SAMPLE_WINDOW:(i+1)*SAMPLE_WINDOW]\n",
    "        sample.to_csv(os.path.join(\n",
    "            DATA_PATH, f'{file_name[0]}_{i}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_names = os.listdir(DATA_PATH)\n",
    "DATA_FFT_PATH = 'data_fft'\n",
    "if not os.path.exists(DATA_FFT_PATH):\n",
    "    os.mkdir(DATA_FFT_PATH)\n",
    "\n",
    "for file_name in files_names:\n",
    "    file_path = os.path.join(DATA_PATH, file_name)\n",
    "    data = pd.read_csv(file_path)\n",
    "    fft_data = np.fft.fft(data)\n",
    "    fft_data = np.abs(fft_data)\n",
    "    np.savetxt(os.path.join(DATA_FFT_PATH, file_name), fft_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(fft_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATE = 0.2\n",
    "TRAIN_SET_PATH = os.path.join(DATA_FFT_PATH, 'train')\n",
    "TEST_SET_PATH = os.path.join(DATA_FFT_PATH, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in files_names:\n",
    "    file_path = os.path.join(DATA_FFT_PATH, file_name)\n",
    "    class_folder = file_name[0]\n",
    "    if not os.path.exists(os.path.join(DATA_FFT_PATH, class_folder)):\n",
    "        os.mkdir(os.path.join(DATA_FFT_PATH, class_folder))\n",
    "    shutil.move(file_path, os.path.join(\n",
    "        DATA_FFT_PATH, class_folder, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_folder = os.listdir(DATA_FFT_PATH)\n",
    "if not os.path.exists(TRAIN_SET_PATH):\n",
    "    os.mkdir(TRAIN_SET_PATH)\n",
    "if not os.path.exists(TEST_SET_PATH):\n",
    "    os.mkdir(TEST_SET_PATH)\n",
    "for class_folder in classes_folder:\n",
    "    files_names = os.listdir(os.path.join(DATA_FFT_PATH, class_folder))\n",
    "    random.shuffle(files_names)\n",
    "    testset_number = int(len(files_names) * TEST_RATE)\n",
    "    testset_files_names = files_names[:testset_number]\n",
    "    trainset_files_names = files_names[testset_number:]\n",
    "\n",
    "    if not os.path.exists(os.path.join(TRAIN_SET_PATH, class_folder)):\n",
    "        os.mkdir(os.path.join(TRAIN_SET_PATH, class_folder))\n",
    "    if not os.path.exists(os.path.join(TEST_SET_PATH, class_folder)):\n",
    "        os.mkdir(os.path.join(TEST_SET_PATH, class_folder))\n",
    "\n",
    "    for testset_file_name in testset_files_names:\n",
    "        file_path = os.path.join(\n",
    "            DATA_FFT_PATH, class_folder, testset_file_name)\n",
    "        shutil.move(file_path, os.path.join(\n",
    "            TEST_SET_PATH, class_folder, testset_file_name))\n",
    "\n",
    "    for trainset_file_name in trainset_files_names:\n",
    "        file_path = os.path.join(\n",
    "            DATA_FFT_PATH, class_folder, trainset_file_name)\n",
    "        shutil.move(file_path, os.path.join(\n",
    "            TRAIN_SET_PATH, class_folder, trainset_file_name))\n",
    "    assert len(os.listdir(os.path.join(DATA_FFT_PATH, class_folder))) == 0  # 确保旧文件夹中的所有图像都被移动走\n",
    "    shutil.rmtree(os.path.join(DATA_FFT_PATH, class_folder))  # 删除文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_MAP = {'n': 0, 't': 1, 'o': 2, 'i': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labbb = []\n",
    "labbb.append(LABELS_MAP['n'])\n",
    "\n",
    "labbb.append(LABELS_MAP['i'])\n",
    "labbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JNUDataset(Dataset):\n",
    "    def __init__(self, data_path, is_train=True):\n",
    "        self.data_path = data_path\n",
    "        if is_train:\n",
    "            path = os.path.join(data_path, 'train')\n",
    "            classes_names = os.listdir(path)\n",
    "        else:\n",
    "            path = os.path.join(data_path, 'test')\n",
    "            classes_names = os.listdir(path)\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for class_name in classes_names:\n",
    "            files_names = os.listdir(os.path.join(path, class_name))\n",
    "            for file_name in files_names:\n",
    "                tmp = pd.read_csv(os.path.join(path, class_name, file_name))\n",
    "                tmp = tmp.values.squeeze().tolist()\n",
    "                self.data.append(tmp)\n",
    "                self.labels.append(LABELS_MAP[class_name])\n",
    "        self.data = torch.tensor(self.data)\n",
    "        self.labels = torch.tensor(self.labels)\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(JNUDataset(DATA_FFT_PATH, is_train=True), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for idx, (data, target) in enumerate(train_loader):\n",
    "    print(f'Batch {idx+1}:')\n",
    "    print(f'Data shape: {data.shape}')\n",
    "    print(f'Target shape: {target}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class JNUDataset(Dataset):\n",
    "#     def __init__(self, data_path, transform=None):\n",
    "#         self.data_path = data_path\n",
    "#         self.transform = transform\n",
    "#         self.files_names = os.listdir(data_path)\n",
    "#     def __len__(self):\n",
    "#         return len(self.files_names)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         file_name = self.files_names[idx]\n",
    "#         class_folder = file_name[0]\n",
    "#         return self.transform(file_name, class_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
